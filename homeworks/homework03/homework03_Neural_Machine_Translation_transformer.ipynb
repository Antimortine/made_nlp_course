{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework №3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Machine Translation in the wild\n",
    "In the third homework you are supposed to get the best translation you can for the EN-RU translation task.\n",
    "\n",
    "Basic approach using RNNs as encoder and decoder is implemented for you. \n",
    "\n",
    "Your ultimate task is to use the techniques we've covered, e.g.\n",
    "\n",
    "* Optimization enhancements (e.g. learning rate decay)\n",
    "\n",
    "* CNN encoder (with or without positional encoding)\n",
    "\n",
    "* attention/self-attention mechanism\n",
    "\n",
    "* pretraining the language model\n",
    "\n",
    "* [Byte Pair Encoding](https://github.com/rsennrich/subword-nmt)\n",
    "\n",
    "* or just fine-tunning BERT ;)\n",
    "\n",
    "to improve the translation quality. \n",
    "\n",
    "__Please use at least three different approaches/models and compare them (translation quality/complexity/training and evaluation time).__\n",
    "\n",
    "Write down some summary on your experiments and illustrate it with convergence plots/metrics and your thoughts. Just like you would approach a real problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "DEVICE_NAME = 'cuda:0'\n",
    "\n",
    "now = datetime.now().strftime(\"%Y-%m-%d--%H-%M-%S\")\n",
    "model_name = f'transformer_{now}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thanks to YSDA NLP course team for the data\n",
    "# (who thanks tilda and deephack teams for the data in their turn)\n",
    "\n",
    "import os\n",
    "path_to_data = '../../datasets/Machine_translation_EN_RU/data.txt'\n",
    "if not os.path.exists(path_to_data):\n",
    "    print(\"Dataset not found locally. Downloading from github.\")\n",
    "    !wget https://raw.githubusercontent.com/neychev/made_nlp_course/master/datasets/Machine_translation_EN_RU/data.txt -nc\n",
    "    path_to_data = './data.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import torchtext\n",
    "from torchtext.data import Field, BucketIterator\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from utils import generate_translation, remove_tech_tokens, get_text, \\\n",
    "                    parse_tensorboard_logs, plot_metrics, beam_search, _len_sort_key, init_weights, count_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main part\n",
    "__Here comes the preprocessing. Do not hesitate to use BPE or more complex preprocessing ;)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_W = WordPunctTokenizer()\n",
    "def tokenize(x, tokenizer=tokenizer_W):\n",
    "    return tokenizer.tokenize(x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC = Field(tokenize=tokenize,\n",
    "            init_token = '<sos>', \n",
    "            eos_token = '<eos>', \n",
    "            lower = True)\n",
    "\n",
    "TRG = Field(tokenize=tokenize,\n",
    "            init_token = '<sos>', \n",
    "            eos_token = '<eos>', \n",
    "            lower = True)\n",
    "\n",
    "dataset = torchtext.data.TabularDataset(\n",
    "    path=path_to_data,\n",
    "    format='tsv',\n",
    "    fields=[('trg', TRG), ('src', SRC)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, valid_data, test_data = dataset.split(split_ratio=[0.8, 0.15, 0.05], random_state=random.seed(SEED))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 40000\n",
      "Number of validation examples: 2500\n",
      "Number of testing examples: 7500\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of training examples: {len(train_data.examples)}\")\n",
    "print(f\"Number of validation examples: {len(valid_data.examples)}\")\n",
    "print(f\"Number of testing examples: {len(test_data.examples)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC.build_vocab(train_data, min_freq=3)\n",
    "TRG.build_vocab(train_data, min_freq=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in source (ru) vocabulary: 9256\n",
      "Unique tokens in target (en) vocabulary: 6734\n"
     ]
    }
   ],
   "source": [
    "print(f\"Unique tokens in source (ru) vocabulary: {len(SRC.vocab)}\")\n",
    "print(f\"Unique tokens in target (en) vocabulary: {len(TRG.vocab)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are tokens from original (RU) corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<unk>',\n",
       " 'террасу',\n",
       " 'чистые',\n",
       " 'компьютеры',\n",
       " 'don',\n",
       " 'шамони',\n",
       " 'logis',\n",
       " 'форму',\n",
       " 'душевые',\n",
       " 'техасского']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SRC.vocab.itos[::1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And from target (EN) corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<unk>', 'springs', 'galeao', 'calm', 'occupies', 'tegel', 'malioboro']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRG.vocab.itos[::1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here is example from train dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "также предлагается доставка продуктов , услуги прачечной и гладильные услуги .\n",
      "other facilities offered at the property include grocery deliveries , laundry and ironing services .\n"
     ]
    }
   ],
   "source": [
    "idx = 9\n",
    "print(' '.join(train_data.examples[idx].src))\n",
    "print(' '.join(train_data.examples[idx].trg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the length distributions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length distribution in Train data\n",
      "Max source length: 73\n",
      "Max target length: 89\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfAAAAEICAYAAACgbaaSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3X+0ZWV93/H3R0Z+qgw/JgRm0MFANehaIpkKFpsaUH5pHdcqUqytgx0zWSlJTBqjkLpCq5DiqhVhJdJMgTAY5YdECwUrmSLUulKQQYwKSBj5NTMBZmQGNBJ/DH77x36uHoZ7uecyd869e+77tdZZZ+/nefY+z77nPud79nOe/exUFZIkqV9eMNMVkCRJU2cAlySphwzgkiT1kAFckqQeMoBLktRDBnBJknrIAK7tluTBJG+agdddnKSSzBv1a0ujluSyJOdsx/Z/n+Tl01mntl/b/wwxgKs3ZuqDQhrTl//BJLckee9gWlW9qKrun6k6ba++/O1HyQA+RyXZZabrIO1s5vLZoEbPAD4LJflgkg1Jvp/k3iTHtfTdknwiyd+1xyeS7NbyTk/ylW32U0kObcuXJbkoyReS/AD4tSR7JPmvSR5K8mSSryTZo5U/OslfJ3kiyd8keeOQdX9BkjOTfCfJ40muTrJvyxvr8lqW5OEk303yHwa23SPJqiRbktyT5ANJ1re8TwEvBf5n6wr8wMDLvmu8/UnTabz/wYH/6eVJHga+1Mp+NsmjrV19OcmrBvZzWZI/TXJDa+O3Jfmllpck5yfZmOR7Sb6Z5NXj1GWfJNcn2dTay/VJFrW8c4F/CvxJq+eftPTBz4O9k1zetn8oyYeSvKDlnd4+Cz7W9v1AkpOG/BvZ/kepqnzMogfwCmAdcFBbXwz8Ulv+MHAr8AvAAuCvgY+0vNOBr2yzrwIObcuXAU8Cx9B9cdsd+FPgFmAhsAvwT4Dd2vrjwMmt7Jvb+oIJ6vwg8Ka2/L5Wx0VtX38GXDFwLAX8d2AP4DXAj4BfbvnnAf8H2Kdt/w1g/XivM8z+fPiY7sdz/A9eDuwF7NHS/y3w4tYGPgF8fWCby1p7eh0wD/g0cGXLOwG4A5gPBPhl4MCB7c5py/sB/wLYs73OZ4H/MfAatwDv3abug58HlwPXtm0XA38LLG95pwM/AX69fS78JvB3QCb7m9j+R/z/ONMV8LHNGwKHAhuBNwEv3CbvO8DJA+snAA+25dOZPIBfPpD3AuAfgNeMU4cPAp/aJu1GYNkEdR5swPcAxw3kHdg+DOYNNLhFA/lfBU5ry/cDJwzkvXfIBjzu/nz4mO7Hc/wPvvw5tpnfyuzd1i8DLh7IPxn4dls+li6YHg28YJv9XEYL4OO8xhHAloH1W5gggNMF5R8Dhw/k/QZwS1s+HVg7kLdn2/YXJ/ub2P5H+7ALfZapqrXA7wL/EdiY5MokB7Xsg4CHBoo/1NKGtW5geX+6s/DvjFPuZcA7Wvf5E0meAN5A1xgn8zLg8wPb3QM8DRwwUObRgeWngBe15YO2qePg8nOZaH/SqPzsfzXJLknOa93I36MLPNC1uTHj/s9W1ZeAP6HrHduYZGWSl2z7Ykn2TPJnrfv7e8CXgfkZbmzL/sALefZnycLx6ldVT7XFYdqV7X+EDOCzUFV9pqreQNcYCvhoy/q7ljbmpS0N4Ad035QBSPKL4+16YPm7wA+BXxqn3Dq6M/D5A4+9quq8Iaq/Djhpm213r6oNQ2z7CF3X2ZiDn6P+0kyY6H9wMP1fAUvpetH2pjtThK5LfPIXqLqwqn4FOBz4R8AfjFPs9+l+bjuqql4C/Oo2r/FcbeW7dGfF236WDNNGJ2P7HyED+CyT5BVJjk03OO2HdN3cP23ZVwAfSrIgyf7AHwF/0fL+BnhVkiOS7E53Bj+hqvopcCnw8SQHtbOG17fX/Qvgnyc5oaXvnuSNY4NkJvHfgHOTvKwdz4IkS4c8/KuBs9oAnYXAb22T/xgw7dexSlMwzP/gi+l+i32c7kv1Hw+78yT/OMlRSV5I96X8h/y8/W/7Gv8APNEGiZ09bD2r6mm6tnZukhe3tvrv+flnyfaw/Y+QAXz22Y1uMMd36bqGfgE4q+WdA6yhG9zxTeBrLY2q+lu6QW7/G7gPeMaI9Am8v+3ndmAz3Zn+C6pqHd0ZxB8Cm+i+Vf8Bw/2/XABcB/xVku/TDWg5aojtaPVfDzzQjuMaug/CMf+Z7gvME0neP+Q+pek0zP/g5XRd0huAu+nawLBeQjcoa0vbx+PAfxmn3CfoBm59t+3/i9vkXwCc0kZ0XzjO9r9N9wXhfrrPis/QfaHfXrb/EUr74V+adZL8Jt2AlH8203WRNFq2/8l5Bq5ZI8mBSY5p15K+gu53vs/PdL0k7Xi2/6lz1iDNJrvSXTd6CPAEcCXwyRmtkaRRsf1PkV3okiT1kF3okiT10KzuQt9///1r8eLFM10Nada74447vltVC2a6Hs/F9iwNZ9j2PKsD+OLFi1mzZs1MV0Oa9ZI8NHmpmWV7loYzbHu2C12SpB4ygEuS1EMGcEmSesgALklSDxnAJUnqIQO4JEk9ZACXJKmHDOCSJPWQAVySpB6a1TOxzUaLz7xh0jIPnveWEdRE0kSGaadgW1W/eQYuSVIPGcAlSeqhoQJ4kt9LcleSbyW5IsnuSQ5JcluStUmuSrJrK7tbW1/b8hcP7Oesln5vkhN2zCFJkrTzmzSAJ1kI/A6wpKpeDewCnAZ8FDi/qg4FtgDL2ybLgS0t/fxWjiSHt+1eBZwIfDLJLtN7OJIkzQ3DdqHPA/ZIMg/YE3gEOBa4puWvAt7elpe2dVr+cUnS0q+sqh9V1QPAWuB1238IkiTNPZMG8KraAHwMeJgucD8J3AE8UVVbW7H1wMK2vBBY17bd2srvN5g+zjY/k2RFkjVJ1mzatOn5HJMkSTu9YbrQ96E7ez4EOAjYi64LfIeoqpVVtaSqlixYsGBHvYwkSb02TBf6m4AHqmpTVf0E+BxwDDC/dakDLAI2tOUNwMEALX9v4PHB9HG2kSRJUzBMAH8YODrJnu237OOAu4GbgVNamWXAtW35urZOy/9SVVVLP62NUj8EOAz46vQchiRJc8ukM7FV1W1JrgG+BmwF7gRWAjcAVyY5p6Vd0ja5BPhUkrXAZrqR51TVXUmupgv+W4EzqurpaT4eSZLmhKGmUq2qs4Gzt0m+n3FGkVfVD4F3TLCfc4Fzp1hHSZK0DWdikySphwzgkiT1kAFckqQeMoBLktRDBnBJknrIAC5JUg8ZwCVJ6iEDuCRJPWQAl3ZCSS5NsjHJtwbS9k2yOsl97Xmflp4kFyZZm+QbSY4c2GZZK39fkmUD6b+S5JttmwvbNMuSRsgALu2cLuPZdw08E7ipqg4DbmrrACfR3ZvgMGAFcBF0AZ9uBsaj6GZdPHss6Lcyvz6w3Q67Q6Gk8Q01lepcsfjMG2a6CtK0qKovJ1m8TfJS4I1teRVwC/DBln55u+nQrUnmJzmwlV1dVZsBkqwGTkxyC/CSqrq1pV8OvB34XzvuiCRtyzNwae44oKoeacuPAge05YXAuoFy61vac6WvHydd0ggZwKU5qJ1t145+nSQrkqxJsmbTpk07+uWkOcUALs0dj7Wucdrzxpa+ATh4oNyilvZc6YvGSX+WqlpZVUuqasmCBQum5SAkdQzg0txxHTA2knwZcO1A+rvbaPSjgSdbV/uNwPFJ9mmD144Hbmx530tydBt9/u6BfUkaEQexSTuhJFfQDULbP8l6utHk5wFXJ1kOPASc2op/ATgZWAs8BbwHoKo2J/kIcHsr9+GxAW3Av6Mb6b4H3eA1B7BJIzZpAE/yCuCqgaSXA38EXN7SFwMPAqdW1Zb2jfwCug+Ep4DTq+prbV/LgA+1/ZxTVaum5zAkDaqqd06Qddw4ZQs4Y4L9XApcOk76GuDV21NHSdtn0i70qrq3qo6oqiOAX6ELyp9neq8plSRJUzDV38CPA75TVQ/RXTs6dga9iu46UBi4prRdJzp2TekJtGtKq2oLsBonf5Ak6XmZagA/DbiiLU/XNaXP4GUnkiRNbugAnmRX4G3AZ7fNm85rSr3sRJKkyU3lDPwk4GtV9Vhbn65rSiVJ0hRNJYC/k593n8M0XVO6XbWXJGmOGuo68CR7AW8GfmMgeTqvKZUkSVMwVACvqh8A+22T9jjTdE2pJEmaGqdSlSSphwzgkiT1kAFckqQeMoBLktRDBnBJknrIAC5JUg8ZwCVJ6iEDuCRJPWQAlySphwzgkiT1kAFckqQeMoBLktRDBnBJknrIAC5JUg8ZwCVJ6iEDuCRJPTRUAE8yP8k1Sb6d5J4kr0+yb5LVSe5rz/u0sklyYZK1Sb6R5MiB/Sxr5e9LsmxHHZQkSTu7Yc/ALwC+WFWvBF4D3AOcCdxUVYcBN7V1gJOAw9pjBXARQJJ9gbOBo4DXAWePBX1JkjQ18yYrkGRv4FeB0wGq6sfAj5MsBd7Yiq0CbgE+CCwFLq+qAm5tZ+8HtrKrq2pz2+9q4ETgiuk7nIktPvOGUbyMJEkjMcwZ+CHAJuDPk9yZ5OIkewEHVNUjrcyjwAFteSGwbmD79S1tovRnSLIiyZokazZt2jS1o5EkaY4YJoDPA44ELqqq1wI/4Ofd5QC0s+2ajgpV1cqqWlJVSxYsWDAdu5TUJPm9JHcl+VaSK5LsnuSQJLe1cStXJdm1ld2tra9t+YsH9nNWS783yQkzdTzSXDZMAF8PrK+q29r6NXQB/bHWNU573tjyNwAHD2y/qKVNlC5pBJIsBH4HWFJVrwZ2AU4DPgqcX1WHAluA5W2T5cCWln5+K0eSw9t2r6L7GeyTSXYZ5bFIGiKAV9WjwLokr2hJxwF3A9cBYyPJlwHXtuXrgHe30ehHA0+2rvYbgeOT7NMGrx3f0iSNzjxgjyTzgD2BR4Bj6b6YQzee5e1teWlbp+UflyQt/cqq+lFVPQCspRuYKmmEJh3E1vw28OnWtXY/8B664H91kuXAQ8CprewXgJPpGvVTrSxVtTnJR4DbW7kPjw1ok7TjVdWGJB8DHgb+Afgr4A7giara2ooNjk352biVqtqa5Elgv5Z+68Cuxx3PAt2YFrqrUXjpS186rccjzXVDBfCq+jqwZJys48YpW8AZE+znUuDSqVRQ0vRoPV9L6QamPgF8lq4LfIepqpXASoAlS5ZMyzgZSR1nYpPmjjcBD1TVpqr6CfA54BhgfutSh2eOTfnZuJWWvzfwOI5nkWYFA7g0dzwMHJ1kz/Zb9th4lpuBU1qZbcezjI1zOQX4Uuthuw44rY1SP4Ru0qavjugYJDXD/gYuqeeq6rYk1wBfA7YCd9J1b98AXJnknJZ2SdvkEuBTSdYCm+lGnlNVdyW5mi74bwXOqKqnR3owkgzg0lxSVWfTTWk86H7GGUVeVT8E3jHBfs4Fzp32Ckoaml3okiT1kGfgkuasYe6R8OB5bxlBTaSp8wxckqQeMoBLktRDBnBJknrIAC5JUg8ZwCVJ6iEDuCRJPWQAlySphwzgkiT1kBO5zCAnkZAkPV+egUuS1ENDnYEneRD4PvA0sLWqliTZF7gKWAw8CJxaVVvabQovAE4GngJOr6qvtf0sAz7UdntOVa2avkOZPYY5s5YkaXtM5Qz816rqiKpa0tbPBG6qqsOAm9o6wEl09wc+DFgBXATQAv7ZwFF0dz46O8k+238IkiTNPdvThb4UGDuDXgW8fSD98urcCsxPciBwArC6qjZX1RZgNXDidry+JElz1rABvIC/SnJHkhUt7YCqeqQtPwoc0JYXAusGtl3f0iZKf4YkK5KsSbJm06ZNQ1ZPkqS5ZdhR6G+oqg1JfgFYneTbg5lVVUlqOipUVSuBlQBLliyZln1KkrSzGeoMvKo2tOeNwOfpfsN+rHWN0543tuIbgIMHNl/U0iZKlyRJUzRpAE+yV5IXjy0DxwPfAq4DlrViy4Br2/J1wLvTORp4snW13wgcn2SfNnjt+JYmSZKmaJgu9AOAz3dXhzEP+ExVfTHJ7cDVSZYDDwGntvJfoLuEbC3dZWTvAaiqzUk+Atzeyn24qjZP25FIkjSHTBrAq+p+4DXjpD8OHDdOegFnTLCvS4FLp15NSZI0yJnYJEnqIQO4JEk9ZACXJKmHvBuZpF7xXgNSxzNwSZJ6yAAuSVIPGcAlSeohA7g0hySZn+SaJN9Ock+S1yfZN8nqJPe1531a2SS5MMnaJN9IcuTAfpa18vclWTbxK0raUQzg0txyAfDFqnol3QRN9wBnAjdV1WHATW0d4CTgsPZYAVwEkGRf4GzgKLr7Ipw9FvQljY4BXJojkuwN/CpwCUBV/biqngCWAqtasVXA29vyUuDy6twKzG83LjoBWF1Vm6tqC7AaOHGEhyIJA7g0lxwCbAL+PMmdSS5uNyg6oN1wCOBRuvsfACwE1g1sv76lTZT+LElWJFmTZM2mTZum8VAkGcCluWMecCRwUVW9FvgBP+8uB352L4OarhesqpVVtaSqlixYsGC6disJA7g0l6wH1lfVbW39GrqA/ljrGqc9b2z5G4CDB7Zf1NImSpc0Qs7EJs0RVfVoknVJXlFV99LdTfDu9lgGnNeer22bXAf8VpIr6QasPVlVjyS5EfjjgYFrxwNnjfJYRmmYmd8ePO8tI6iJ9EwGcGlu+W3g00l2Be4H3kPXE3d1kuXAQ8CprewXgJOBtcBTrSxVtTnJR4DbW7kPV9Xm0R2CJDCAS3NKVX0dWDJO1nHjlC3gjAn2cylw6fTWTtJUDP0beJJd2sjV69v6IUlua5M8XNW+0ZNkt7a+tuUvHtjHWS393iQnTPfBSJI0V0xlENv76CZ9GPNR4PyqOhTYAixv6cuBLS39/FaOJIcDpwGvortm9JNJdtm+6kuSNDcNFcCTLALeAlzc1gMcSzeKFZ49+cPYpBDXAMe18kuBK6vqR1X1AN3vaq+bjoOQJGmuGfYM/BPAB4CftvX9gCeqamtbH5zI4WeTPLT8J1v5oSZ/cOIHSZImN2kAT/JWYGNV3TGC+jjxgyRJQxhmFPoxwNuSnAzsDryE7oYI85PMa2fZgxM5jE3ysD7JPGBv4HGc/EGSpGkz6Rl4VZ1VVYuqajHdILQvVdW7gJuBU1qxbSd/GLu94CmtfLX009oo9UPo7nD01Wk7EkmS5pDtuQ78g8CVSc4B7qTd4ag9fyrJWmAzXdCnqu5KcjXdrE9bgTOq6unteH1JkuasKQXwqroFuKUt3884o8ir6ofAOybY/lzg3KlWUpIkPZM3M5EkqYcM4JIk9ZABXJKkHjKAS5LUQwZwSZJ6yAAuSVIPGcAlSeohA7gkST1kAJckqYcM4JIk9ZABXJKkHjKAS5LUQ9tzNzKNwOIzb5i0zIPnvWUENZEkzSaegUuS1EMGcEmSesgudEnaTv7UpZkw6Rl4kt2TfDXJ3yS5K8l/aumHJLktydokVyXZtaXv1tbXtvzFA/s6q6Xfm+SEHXVQkiTt7IbpQv8RcGxVvQY4AjgxydHAR4Hzq+pQYAuwvJVfDmxp6ee3ciQ5HDgNeBVwIvDJJLtM58FIkjRXTBrAq/P3bfWF7VHAscA1LX0V8Pa2vLSt0/KPS5KWfmVV/aiqHgDWAq+blqOQNLQkuyS5M8n1bd3eNKmHhhrE1hr814GNwGrgO8ATVbW1FVkPLGzLC4F1AC3/SWC/wfRxtpE0Ou8D7hlYtzdN6qGhAnhVPV1VRwCL6M6aX7mjKpRkRZI1SdZs2rRpR72MNCclWQS8Bbi4rQd706RemtJlZFX1BHAz8HpgfpKxUeyLgA1teQNwMEDL3xt4fDB9nG0GX2NlVS2pqiULFiyYSvUkTe4TwAeAn7b1/bA3TeqlYUahL0gyvy3vAbyZrvvtZuCUVmwZcG1bvq6t0/K/VFXV0k9rv6sdAhwGfHW6DkTSc0vyVmBjVd0xwte0R03aQYa5DvxAYFX7jesFwNVVdX2Su4Erk5wD3Alc0spfAnwqyVpgM91vZVTVXUmuBu4GtgJnVNXT03s4kp7DMcDbkpwM7A68BLiA1pvWzrLH601b/3x606DrUQNWAixZsqSm/YikOWzSAF5V3wBeO076/Yzzu1dV/RB4xwT7Ohc4d+rVlLS9quos4CyAJG8E3l9V70ryWbresisZvzft/zHQm5bkOuAzST4OHIS9adKMcCY2SR/E3jSpdwzg0hxUVbcAt7Rle9OkHvJmJpIk9ZABXJKkHjKAS5LUQwZwSZJ6yAAuSVIPGcAlSeohA7gkST1kAJckqYcM4JIk9ZABXJKkHjKAS5LUQwZwSZJ6yAAuSVIPGcAlSeqhSQN4koOT3Jzk7iR3JXlfS983yeok97XnfVp6klyYZG2SbyQ5cmBfy1r5+5Is23GHJUnSzm2YM/CtwO9X1eHA0cAZSQ4HzgRuqqrDgJvaOsBJwGHtsQK4CLqAD5wNHEV37+Gzx4K+JEmamkkDeFU9UlVfa8vfB+4BFgJLgVWt2Crg7W15KXB5dW4F5ic5EDgBWF1Vm6tqC7AaOHFaj0aSpDliSr+BJ1kMvBa4DTigqh5pWY8CB7TlhcC6gc3Wt7SJ0iVJ0hQNHcCTvAj4S+B3q+p7g3lVVUBNR4WSrEiyJsmaTZs2TccuJUna6QwVwJO8kC54f7qqPteSH2td47TnjS19A3DwwOaLWtpE6c9QVSuraklVLVmwYMFUjkWSpDljmFHoAS4B7qmqjw9kXQeMjSRfBlw7kP7uNhr9aODJ1tV+I3B8kn3a4LXjW5okSZqieUOUOQb4N8A3k3y9pf0hcB5wdZLlwEPAqS3vC8DJwFrgKeA9AFW1OclHgNtbuQ9X1eZpOQpJkuaYSQN4VX0FyATZx41TvoAzJtjXpcClU6mgJEl6NmdikySphwzgkiT1kAFckqQeMoBLktRDBnBJknpomMvINMstPvOGScs8eN5bRlATzWZJDgYup5v2uICVVXVBu9HQVcBi4EHg1Kra0uaAuIDustCngNPH7ovQ7ib4obbrc6pqFZJGyjNwae7wzoLSTsQALs0R3llQ2rkYwKU5aFR3FvTmRNKOYwCX5phR3Vmw7c+bE0k7iAFcmkNGeWdBSTuWAVyaI7yzoLRz8TKyOWKYS83Ay812ct5ZcAbZBjXdDODSHOGdBaWdi13okiT1kAFckqQeMoBLktRDkwbwJJcm2ZjkWwNp+yZZneS+9rxPS0+SC5OsTfKNJEcObLOslb+vzaMsSZKep2HOwC/j2dMkOneyJEkzaNIAXlVfBra9RMS5kyVJmkHP9zdw506WJGkGbfcgNudOliRp9J7vRC6PJTmwqh6ZwtzJb9wm/Zbn+dqStNMaZsY2Z2sTPP8zcOdOliRpBk16Bp7kCrqz5/2TrKcbTe7cyZIkzaBJA3hVvXOCLOdOliRphjgTmyRJPWQAlySphwzgkiT1kAFckqQeer7XgWsn5TWoktQPnoFLktRDBnBJknrILnRNmd3skjTzPAOXJKmHDOCSJPWQXeiSZo1hfp6RP2Op4xm4JEk95Bm4dgjPECRpx9opArjdbpKkucYudEmSeminOAOXJD2TP2Pt/EYewJOcCFwA7AJcXFXnjboOmh38gOk323L/2Qb7baQBPMkuwJ8CbwbWA7cnua6q7h5lPdQfw45v8ENmtGzL0swb9Rn464C1VXU/QJIrgaWAjV7bZboGMvpFYGi25TliOgcJ276m16gD+EJg3cD6euCowQJJVgAr2urfJ7l3gn3tD3x32ms4MzyWWSIffVZSX47nZSN+vUnbMuyU7dl6bocet69R13Oo9jzrBrFV1Upg5WTlkqypqiUjqNIO57HMXjvb8Yzaztaeref0sp7bZ9SXkW0ADh5YX9TSJPWLbVmaYaMO4LcDhyU5JMmuwGnAdSOug6TtZ1uWZthIu9CramuS3wJupLv05NKquut57m7Sbrke8Vhmr53teKbFNLdl6M/f2XpOL+u5HVJVM10HSZI0RU6lKklSDxnAJUnqod4F8CQnJrk3ydokZ850faYqycFJbk5yd5K7kryvpe+bZHWS+9rzPjNd12El2SXJnUmub+uHJLmtvUdXtUFOs16S+UmuSfLtJPckeX2f35c+mK3tuW/ttA9tsC/tK8nvtff8W0muSLL7bPx7Qs8C+MD0jScBhwPvTHL4zNZqyrYCv19VhwNHA2e0YzgTuKmqDgNuaut98T7gnoH1jwLnV9WhwBZg+YzUauouAL5YVa8EXkN3TH1+X2a1Wd6e+9ZO+9AGZ337SrIQ+B1gSVW9mm6A5mnMzr8nVFVvHsDrgRsH1s8Czprpem3nMV1LN5/0vcCBLe1A4N6ZrtuQ9V9E1/COBa4HQjdj0bzx3rPZ+gD2Bh6gDewcSO/l+9KHR5/a82xup31og31pX/x8hsF96a7Suh44Ybb9PccevToDZ/zpGxfOUF22W5LFwGuB24ADquqRlvUocMAMVWuqPgF8APhpW98PeKKqtrb1vrxHhwCbgD9vXZEXJ9mL/r4vfdCL9tyDdtqHNtiL9lVVG4CPAQ8DjwBPAncw+/6eQM+60HcmSV4E/CXwu1X1vcG86r7mzfrr+5K8FdhYVXfMdF2mwTzgSOCiqnot8AO26c7ry/ui6TPb22mP2mAv2lf7DX4p3ReOg4C9gBNnsk7PpW8BfKeYvjHJC+k+FD5dVZ9ryY8lObDlHwhsnKn6TcExwNuSPAhcSdeFdwEwP8nYJEF9eY/WA+ur6ra2fg3dB04f35e+mNXtuSfttC9tsC/t603AA1W1qap+AnyO7m882/6eQP8CeO+nb0wS4BLgnqr6+EDWdcCytryM7je3Wa2qzqqqRVW1mO69+FJVvQu4GTilFevLsTwKrEvyipZ0HN2tMXv3vvTIrG3PfWmnfWmDPWpfDwNHJ9mz/Q+M1XNW/T3H9G4mtiQn0/3mMzZ947kzXKUpSfIG4P8C3+Tnv1n9Id3va1cDLwUeAk6tqs0zUsnnIckbgfdX1VuTvJzubGBf4E7gX1fVj2ayfsNIcgRwMbArcD/wHrovub19X2a72dqe+9hOZ3sb7Ev7SvKfgH9JdyXCncB76X7znlV/T+hhAJckSf3rQpckSRjAJUm2JSFCAAAAJElEQVTqJQO4JEk9ZACXJKmHDOCSJPWQAVySpB4ygEuS1EP/Hx2y3j0ma3M2AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 576x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "src_length = list(map(len, [x.src for x in train_data.examples]))\n",
    "trg_length = list(map(len, [x.trg for x in train_data.examples]))\n",
    "\n",
    "print('Length distribution in Train data')\n",
    "print(f'Max source length: {max(src_length)}')\n",
    "print(f'Max target length: {max(trg_length)}')\n",
    "plt.figure(figsize=[8, 4])\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"source length\")\n",
    "plt.hist(list(src_length), bins=20);\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"translation length\")\n",
    "plt.hist(list(trg_length), bins=20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length distribution in Validation data\n",
      "Max source length: 76\n",
      "Max target length: 73\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "src_length = list(map(len, [x.src for x in valid_data.examples]))\n",
    "trg_length = list(map(len, [x.trg for x in valid_data.examples]))\n",
    "\n",
    "print('Length distribution in Validation data')\n",
    "print(f'Max source length: {max(src_length)}')\n",
    "print(f'Max target length: {max(trg_length)}')\n",
    "plt.figure(figsize=[8, 4])\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"source length\")\n",
    "plt.hist(list(src_length), bins=20);\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"translation length\")\n",
    "plt.hist(list(trg_length), bins=20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length distribution in Test data\n",
      "Max source length: 80\n",
      "Max target length: 99\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "src_length = list(map(len, [x.src for x in test_data.examples]))\n",
    "trg_length = list(map(len, [x.trg for x in test_data.examples]))\n",
    "\n",
    "print('Length distribution in Test data')\n",
    "print(f'Max source length: {max(src_length)}')\n",
    "print(f'Max target length: {max(trg_length)}')\n",
    "plt.figure(figsize=[8, 4])\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"source length\")\n",
    "plt.hist(list(src_length), bins=20);\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"translation length\")\n",
    "plt.hist(list(trg_length), bins=20);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model side\n",
    "__Here comes simple pipeline of NMT model learning. It almost copies the week03 practice__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(DEVICE_NAME if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_bleu(model, test_iterator, target_vocab=TRG.vocab, beam_width=1, with_tqdm=True):\n",
    "    assert beam_width > 0\n",
    "    original_text = []\n",
    "    generated_text = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        if with_tqdm:\n",
    "            test_iterator = tqdm(test_iterator, position=0, leave=True)\n",
    "        for i, batch in enumerate(test_iterator):\n",
    "            src = batch.src # [src sent len, batch size]\n",
    "            trg = batch.trg # [trg sent len, batch size]\n",
    "            \n",
    "            if beam_width == 1:\n",
    "                output = model(src, trg, 0) #turn off teacher forcing\n",
    "                #output = [trg sent len, batch size, output dim]\n",
    "\n",
    "                output = output.argmax(dim=-1) # [trg sent len, batch size]\n",
    "            else:\n",
    "                output = beam_search(model, src, trg, target_vocab, beam_width)  # [trg sent len, batch size]\n",
    "\n",
    "            original_text.extend([get_text(x, target_vocab) for x in trg.cpu().numpy().T])\n",
    "            generated_text.extend([get_text(x, target_vocab) for x in output[1:].detach().cpu().numpy().T])\n",
    "    return corpus_bleu([[text] for text in original_text], generated_text) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_teacher_forcing_ratio(epoch, base_teacher_forcing_ratio=0.5, decay=1):\n",
    "    return base_teacher_forcing_ratio * decay ** epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion, clip, epoch):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for i, batch in enumerate(iterator):        \n",
    "        src = batch.src[:MAX_LEN] # [src sent len, batch size]\n",
    "        trg = batch.trg[:MAX_LEN] # [trg sent len, batch size]\n",
    "        \n",
    "        optimizer.zero_grad()        \n",
    "        teacher_forcing_ratio = get_teacher_forcing_ratio(epoch)\n",
    "        output = model(src, trg, teacher_forcing_ratio) # [trg sent len, batch size, output dim]\n",
    "        \n",
    "        output = output[1:].view(-1, output.shape[-1]) # [(trg sent len - 1) * batch size, output dim]\n",
    "        trg = trg[1:].view(-1) # [(trg sent len - 1) * batch size]\n",
    "        \n",
    "        loss = criterion(output, trg)        \n",
    "        loss.backward()\n",
    "        \n",
    "        # Let's clip the gradient\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        \n",
    "        optimizer.step()        \n",
    "        batch_loss = loss.item()\n",
    "        epoch_loss += batch_loss\n",
    "        \n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):    \n",
    "    model.eval()    \n",
    "    epoch_loss = 0    \n",
    "    with torch.no_grad():    \n",
    "        for i, batch in enumerate(iterator):\n",
    "            src = batch.src[:MAX_LEN] # [src sent len, batch size]\n",
    "            trg = batch.trg[:MAX_LEN] # [trg sent len, batch size]\n",
    "\n",
    "            output = model(src, trg, 0) #turn off teacher forcing\n",
    "            # [trg sent len, batch size, output dim]\n",
    "\n",
    "            output = output[1:].view(-1, output.shape[-1]) # [(trg sent len - 1) * batch size]\n",
    "            trg = trg[1:].view(-1) # [(trg sent len - 1) * batch size, output dim]\n",
    "\n",
    "            loss = criterion(output, trg)            \n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_procedure(model, model_name, train_iterator, valid_iterator,\n",
    "                      optimizer, lr_scheduler, criterion, writer, clip, n_epochs, beam_width=None):\n",
    "    best_valid_bleu = float('-inf')\n",
    "    for epoch in tqdm(range(n_epochs)):    \n",
    "        start_time = time.time()\n",
    "        \n",
    "        train_loss = train(model, train_iterator, optimizer, criterion, clip, epoch)\n",
    "        valid_loss = evaluate(model, valid_iterator, criterion)\n",
    "        lr_scheduler.step(valid_loss)\n",
    "\n",
    "        end_time = time.time()\n",
    "        epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "        \n",
    "        valid_bleu_greedy = eval_bleu(model, valid_iterator, beam_width=1, with_tqdm=False)\n",
    "        writer.add_scalar('Validation BLEU (Greedy)',\n",
    "                    valid_bleu_greedy,\n",
    "                    epoch)\n",
    "        \n",
    "        if beam_width is None:\n",
    "            valid_bleu_beam = float('-inf')\n",
    "        else:\n",
    "            valid_bleu_beam = eval_bleu(model, valid_iterator, beam_width=beam_width, with_tqdm=False)\n",
    "            writer.add_scalar(f'Validation BLEU (BeamSearch@{beam_width})',\n",
    "                        valid_bleu_beam,\n",
    "                        epoch)\n",
    "        \n",
    "        max_bleu = max(valid_bleu_greedy, valid_bleu_beam)\n",
    "        if max_bleu > best_valid_bleu:\n",
    "            best_valid_bleu = max_bleu\n",
    "            torch.save(model.state_dict(), f'models/{model_name}.pt')\n",
    "\n",
    "        writer.add_scalar('Train loss',\n",
    "                    train_loss,\n",
    "                    epoch)\n",
    "        writer.add_scalar('Validation loss',\n",
    "                    valid_loss,\n",
    "                    epoch)\n",
    "        print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "        print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {np.exp(train_loss):7.3f}')\n",
    "        print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {np.exp(valid_loss):7.3f}')\n",
    "        if beam_width is None:\n",
    "            print(f'\\tVal. BLEU (Greedy): {valid_bleu_greedy:.3f}')\n",
    "        else:\n",
    "            print(f'\\tVal. BLEU (Greedy): {valid_bleu_greedy:.3f} | Val. BLEU (BeamSearch@{beam_width}): {valid_bleu_beam:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tensorboard_dir(model_name):\n",
    "    return f'runs/{model_name}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_samples(model, test_iterator, indices=range(0, 10), beam_widths=[2,10]):\n",
    "    batch = next(iter(test_iterator))\n",
    "    for idx in indices:\n",
    "        src = batch.src[:, idx:idx+1]\n",
    "        trg = batch.trg[:, idx:idx+1]\n",
    "        generate_translation(src, trg, model, TRG.vocab, beam_widths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's use Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data), \n",
    "    batch_size = BATCH_SIZE, \n",
    "    device = device,\n",
    "    sort_key=_len_sort_key\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = len(SRC.vocab)\n",
    "OUTPUT_DIM = len(TRG.vocab)\n",
    "HID_DIM = 256\n",
    "N_HEADS = 4\n",
    "N_LAYERS = 4\n",
    "ENC_DROPOUT = 0.1\n",
    "DEC_DROPOUT = 0.1\n",
    "\n",
    "LR = 0.5e-3\n",
    "CLIP = 1\n",
    "N_EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchnlp.nn.attention import Attention\n",
    "\n",
    "import random\n",
    "\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=100):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-np.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)\n",
    "\n",
    "\n",
    "class TransformerEncoder(nn.Module):\n",
    "    def __init__(self, input_dim, hid_dim, n_heads, n_layers, dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.input_dim = input_dim\n",
    "        self.hid_dim = hid_dim\n",
    "        self.n_heads = n_heads\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.embedding = nn.Embedding(\n",
    "            num_embeddings=input_dim,\n",
    "            embedding_dim=hid_dim\n",
    "        )\n",
    "        \n",
    "        self.pos_encoder = PositionalEncoding(hid_dim, dropout)\n",
    "        encoder_layers = nn.TransformerEncoderLayer(hid_dim, n_heads, hid_dim, dropout)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, n_layers)\n",
    "        \n",
    "    def forward(self, src, key_padding_mask=None):        \n",
    "        # src = [src sent len, batch size]\n",
    "        # key_padding_mask = [batch size, src sent len]\n",
    "        embedded = self.embedding(src) * np.sqrt(self.hid_dim) # [src sent len, batch size, hid dim]\n",
    "        embedded = self.pos_encoder(embedded)\n",
    "        \n",
    "        # [src sent len, batch size, hid dim]\n",
    "        output = self.transformer_encoder(embedded, src_key_padding_mask=key_padding_mask)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerDecoder(nn.Module):\n",
    "    def __init__(self, output_dim, hid_dim, n_heads, n_layers, dropout):\n",
    "        super().__init__()\n",
    "\n",
    "        self.hid_dim = hid_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.n_heads = n_heads\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.embedding = nn.Embedding(\n",
    "            num_embeddings=output_dim,\n",
    "            embedding_dim=hid_dim\n",
    "        )\n",
    "        \n",
    "        self.pos_encoder = PositionalEncoding(hid_dim, dropout)\n",
    "        decoder_layers = nn.TransformerDecoderLayer(hid_dim, n_heads, hid_dim, dropout)\n",
    "        self.transformer_decoder = nn.TransformerDecoder(decoder_layers, n_layers)\n",
    "        \n",
    "        self.out = nn.Linear(\n",
    "            in_features=hid_dim,\n",
    "            out_features=output_dim\n",
    "        )\n",
    "        \n",
    "    def forward(self, input, encoder_outputs, key_padding_mask=None):        \n",
    "        # input = [src prefix len, batch size]\n",
    "        # encoder_outputs = [src sent len, batch size, hid dim]\n",
    "        \n",
    "        embedded = self.embedding(input) * np.sqrt(self.hid_dim) # [src prefix len, batch size, hid dim]\n",
    "        embedded = self.pos_encoder(embedded) # [src prefix len, batch size, hid dim]\n",
    "        \n",
    "        # [src prefix len, batch size, hid dim]\n",
    "        outputs = self.transformer_decoder(embedded, encoder_outputs, tgt_key_padding_mask=key_padding_mask)\n",
    "        \n",
    "        output = self.out(outputs[-1]) # [batch size, output dim]\n",
    "        return output\n",
    "\n",
    "\n",
    "class TransformerSeq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, src_pad_idx, trg_pad_idx, device):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.src_pad_idx = src_pad_idx\n",
    "        self.trg_pad_idx = trg_pad_idx\n",
    "        self.device = device\n",
    "    \n",
    "    def apply_encoder(self, src):\n",
    "        # src = [src sent len, batch size]\n",
    "        \n",
    "        key_padding_mask = (src == self.src_pad_idx).transpose(1,0)\n",
    "        enc_output = self.encoder(src, key_padding_mask=key_padding_mask)\n",
    "        return enc_output # [src sent len, batch size, emb dim]\n",
    "    \n",
    "    def forward(self, src, trg, teacher_forcing_ratio=0.5):        \n",
    "        # src = [src sent len, batch size]\n",
    "        # trg = [trg sent len, batch size]\n",
    "        # teacher_forcing_ratio is probability to use teacher forcing\n",
    "        # e.g. if teacher_forcing_ratio is 0.75 we use ground-truth inputs 75% of the time\n",
    "        \n",
    "        batch_size = trg.shape[1]\n",
    "        max_len = trg.shape[0]\n",
    "        trg_vocab_size = self.decoder.output_dim\n",
    "        \n",
    "        # encoder_output = [src sent len, batch size, hid dim]\n",
    "        encoder_output = self.apply_encoder(src)\n",
    "        decoder_outputs = torch.zeros(max_len, batch_size, trg_vocab_size).to(self.device)\n",
    "        decoder_inputs = torch.full((max_len, batch_size), self.trg_pad_idx, dtype=torch.long, device=self.device)\n",
    "        \n",
    "        # first input to the decoder is the <sos> tokens\n",
    "        decoder_inputs[0,:] = trg[0,:]\n",
    "        \n",
    "        for t in range(1, max_len):\n",
    "            input = decoder_inputs[:t].clone().detach()\n",
    "            key_padding_mask = (input == self.trg_pad_idx).transpose(1,0)\n",
    "            \n",
    "            # output = [batch size, output dim]\n",
    "            output = self.decoder(input, encoder_output, key_padding_mask)\n",
    "            decoder_outputs[t] = output\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "            top1 = output.detach().max(1)[1]\n",
    "            decoder_inputs[t] = (trg[t] if teacher_force else top1)\n",
    "        \n",
    "        return decoder_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC_PAD_IDX = SRC.vocab.stoi['<pad>']\n",
    "TRG_PAD_IDX = TRG.vocab.stoi['<pad>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from models import GruEncoder, AttentionGruDecoder, AttentionGruSeq2Seq\n",
    "enc = TransformerEncoder(INPUT_DIM, HID_DIM, N_HEADS, N_LAYERS, ENC_DROPOUT)\n",
    "dec = TransformerDecoder(OUTPUT_DIM, HID_DIM, N_HEADS, N_LAYERS, DEC_DROPOUT)\n",
    "model = TransformerSeq2Seq(enc, dec, SRC_PAD_IDX, TRG_PAD_IDX, device).to(device)\n",
    "\n",
    "for p in model.parameters():\n",
    "    if p.dim() > 1:\n",
    "        nn.init.xavier_uniform_(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10045006"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.AdamW(model.parameters(), lr=LR, weight_decay=0.001, amsgrad=True)\n",
    "lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.3, patience=2)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=TRG_PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runs/transformer_2020-05-29--22-19-26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|█         | 1/10 [21:11<3:10:46, 1271.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 20m 57s\n",
      "\tTrain Loss: 4.482 | Train PPL:  88.372\n",
      "\t Val. Loss: 4.812 |  Val. PPL: 122.933\n",
      "\tVal. BLEU (Greedy): 9.106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 2/10 [42:26<2:49:42, 1272.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 02 | Time: 20m 59s\n",
      "\tTrain Loss: 3.670 | Train PPL:  39.259\n",
      "\t Val. Loss: 4.693 |  Val. PPL: 109.203\n",
      "\tVal. BLEU (Greedy): 12.820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███       | 3/10 [1:03:43<2:28:37, 1273.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 03 | Time: 21m 1s\n",
      "\tTrain Loss: 3.394 | Train PPL:  29.771\n",
      "\t Val. Loss: 4.674 |  Val. PPL: 107.075\n",
      "\tVal. BLEU (Greedy): 13.732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 4/10 [1:25:04<2:07:36, 1276.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 04 | Time: 21m 6s\n",
      "\tTrain Loss: 3.230 | Train PPL:  25.275\n",
      "\t Val. Loss: 4.484 |  Val. PPL:  88.622\n",
      "\tVal. BLEU (Greedy): 14.983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 5/10 [1:46:19<1:46:18, 1275.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 05 | Time: 20m 59s\n",
      "\tTrain Loss: 3.116 | Train PPL:  22.550\n",
      "\t Val. Loss: 4.507 |  Val. PPL:  90.615\n",
      "\tVal. BLEU (Greedy): 16.063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 6/10 [2:07:30<1:24:57, 1274.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 06 | Time: 20m 57s\n",
      "\tTrain Loss: 3.046 | Train PPL:  21.030\n",
      "\t Val. Loss: 4.504 |  Val. PPL:  90.360\n",
      "\tVal. BLEU (Greedy): 16.596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████   | 7/10 [2:28:46<1:03:44, 1274.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 07 | Time: 21m 0s\n",
      "\tTrain Loss: 2.983 | Train PPL:  19.752\n",
      "\t Val. Loss: 4.381 |  Val. PPL:  79.907\n",
      "\tVal. BLEU (Greedy): 17.051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 8/10 [2:49:48<42:21, 1270.95s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 08 | Time: 20m 46s\n",
      "\tTrain Loss: 2.898 | Train PPL:  18.136\n",
      "\t Val. Loss: 4.520 |  Val. PPL:  91.846\n",
      "\tVal. BLEU (Greedy): 17.323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████ | 9/10 [3:11:17<21:16, 1276.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 09 | Time: 21m 14s\n",
      "\tTrain Loss: 2.833 | Train PPL:  16.990\n",
      "\t Val. Loss: 4.472 |  Val. PPL:  87.504\n",
      "\tVal. BLEU (Greedy): 17.714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 10/10 [3:32:32<00:00, 1275.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 | Time: 20m 56s\n",
      "\tTrain Loss: 2.796 | Train PPL:  16.377\n",
      "\t Val. Loss: 4.573 |  Val. PPL:  96.828\n",
      "\tVal. BLEU (Greedy): 19.016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tensorboard_dir = get_tensorboard_dir(model_name)\n",
    "print(tensorboard_dir)\n",
    "writer = SummaryWriter(tensorboard_dir)\n",
    "training_procedure(model, model_name, train_iterator, valid_iterator,\n",
    "                      optimizer, lr_scheduler, criterion, writer, clip=CLIP, n_epochs=N_EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's load best model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'models/{model_name}.pt', 'rb') as fp:\n",
    "    best_state_dict = torch.load(fp, map_location='cpu')\n",
    "    model.load_state_dict(best_state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**And look at its predictions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:                   towels are featured .\n",
      "Generated (Greedy):         towels are provided .\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-b20a87292398>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-26-43e1d5a998dd>\u001b[0m in \u001b[0;36mprint_samples\u001b[0;34m(model, test_iterator, indices, beam_widths)\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0msrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mtrg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mgenerate_translation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTRG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeam_widths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/work/Data/made/made_nlp_course/homeworks/homework03/utils.py\u001b[0m in \u001b[0;36mgenerate_translation\u001b[0;34m(src, trg, model, TRG_vocab, beam_widths)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mbeam_width\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbeam_widths\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbeam_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTRG_vocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeam_width\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m             \u001b[0mgenerated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTRG_vocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Generated (BeamSearch@{}):\\t{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeam_width\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerated\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpandtabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtabs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/work/Data/made/made_nlp_course/homeworks/homework03/utils.py\u001b[0m in \u001b[0;36mbeam_search\u001b[0;34m(model, src, trg, target_vocab, k)\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0meos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget_vocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstoi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'<eos>'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     pred_tokens = [beam_search_for_sample(model, src[:,i,None], trg[:,i,None], eos, k).unsqueeze(1)\n\u001b[0;32m--> 105\u001b[0;31m             for i in range(src.shape[1])]\n\u001b[0m\u001b[1;32m    106\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_tokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# [trg sent len, batch size]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/work/Data/made/made_nlp_course/homeworks/homework03/utils.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0meos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget_vocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstoi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'<eos>'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     pred_tokens = [beam_search_for_sample(model, src[:,i,None], trg[:,i,None], eos, k).unsqueeze(1)\n\u001b[0;32m--> 105\u001b[0;31m             for i in range(src.shape[1])]\n\u001b[0m\u001b[1;32m    106\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_tokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# [trg sent len, batch size]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/work/Data/made/made_nlp_course/homeworks/homework03/utils.py\u001b[0m in \u001b[0;36mbeam_search_for_sample\u001b[0;34m(model, src, trg, eos, k)\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;31m# encoder_states = [batch size = 1, src sent len, dimensions = n layers * hid dim]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;31m# hidden = [n layers * n directions, batch size = 1, hid dim]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mencoder_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;31m# first input to the decoder is the <sos> tokens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "print_samples(model, test_iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Test BLEU (Greedy):', eval_bleu(model, test_iterator, beam_width=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Test BLEU (BeamSearch@2):', eval_bleu(model, test_iterator, beam_width=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Test BLEU (BeamSearch@5):', eval_bleu(model, test_iterator, beam_width=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Test BLEU (BeamSearch@10):', eval_bleu(model, test_iterator, beam_width=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Test BLEU (BeamSearch@16):', eval_bleu(model, test_iterator, beam_width=16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Test BLEU (BeamSearch@32):', eval_bleu(model, test_iterator, beam_width=32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**And plot train/val metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs = parse_tensorboard_logs(tensorboard_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printable_model_name = '_'.join(model_name.split('_')[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics(logs, printable_model_name)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "homework.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
